{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca3272b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T12:20:41.400571Z",
     "start_time": "2022-03-04T12:20:01.861171Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "430/430 [==============================] - 7s 15ms/step - loss: 0.5630 - accuracy: 0.7634 - val_loss: 0.2378 - val_accuracy: 0.9202\n",
      "Epoch 2/5\n",
      "430/430 [==============================] - 7s 15ms/step - loss: 0.2248 - accuracy: 0.9174 - val_loss: 0.1192 - val_accuracy: 0.9662\n",
      "Epoch 3/5\n",
      "430/430 [==============================] - 7s 15ms/step - loss: 0.1228 - accuracy: 0.9585 - val_loss: 0.0478 - val_accuracy: 0.9841\n",
      "Epoch 4/5\n",
      "430/430 [==============================] - 7s 15ms/step - loss: 0.0710 - accuracy: 0.9783 - val_loss: 0.0421 - val_accuracy: 0.9886\n",
      "Epoch 5/5\n",
      "430/430 [==============================] - 7s 15ms/step - loss: 0.0422 - accuracy: 0.9869 - val_loss: 0.0245 - val_accuracy: 0.9894\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.0180 - accuracy: 0.9927\n",
      "Accuracy: 99.267101\n",
      "loss: 0.018002\n"
     ]
    }
   ],
   "source": [
    "# 필요한 모듈 임포트\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, Dropout, Conv1D, GlobalMaxPool1D, concatenate\n",
    "\n",
    "# 데이터 읽어오기\n",
    "train_file = \"./traindata.csv\"\n",
    "data = pd.read_csv(train_file, delimiter=',')\n",
    "features = data['question'].tolist()\n",
    "labels = data['label'].tolist()\n",
    "\n",
    "# 단어 인덱스 시퀀스 벡터\n",
    "corpus = [preprocessing.text.text_to_word_sequence(text) for text in features]\n",
    "\n",
    "tokenizer = preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "sequences = tokenizer.texts_to_sequences(corpus)\n",
    "word_index = tokenizer.word_index\n",
    "MAX_SEQ_LEN = 15  # 단어 시퀀스 벡터 크기\n",
    "padded_seqs = preprocessing.sequence.pad_sequences(sequences, maxlen=MAX_SEQ_LEN, padding='post')\n",
    "\n",
    "# 학습용, 검증용, 테스트용 데이터셋 생성 ➌\n",
    "# 학습셋:검증셋:테스트셋 = 7:2:1\n",
    "ds = tf.data.Dataset.from_tensor_slices((padded_seqs, labels))\n",
    "ds = ds.shuffle(len(features))\n",
    "train_size = int(len(padded_seqs) * 0.7)\n",
    "val_size = int(len(padded_seqs) * 0.2)\n",
    "test_size = int(len(padded_seqs) * 0.1)\n",
    "train_ds = ds.take(train_size).batch(20)\n",
    "val_ds = ds.skip(train_size).take(val_size).batch(20)\n",
    "test_ds = ds.skip(train_size + val_size).take(test_size).batch(20)\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "dropout_prob = 0.5\n",
    "EMB_SIZE = 128\n",
    "EPOCH = 5\n",
    "VOCAB_SIZE = len(word_index) + 1  # 전체 단어 수\n",
    "\n",
    "# CNN 모델 정의\n",
    "input_layer = Input(shape=(MAX_SEQ_LEN,))\n",
    "embedding_layer = Embedding(VOCAB_SIZE, EMB_SIZE, input_length=MAX_SEQ_LEN)(input_layer)\n",
    "dropout_emb = Dropout(rate=dropout_prob)(embedding_layer)\n",
    "\n",
    "conv1 = Conv1D(filters=128, kernel_size=3, padding='valid', activation=tf.nn.relu)(dropout_emb)\n",
    "pool1 = GlobalMaxPool1D()(conv1)\n",
    "conv2 = Conv1D(filters=128, kernel_size=4, padding='valid', activation=tf.nn.relu)(dropout_emb)\n",
    "pool2 = GlobalMaxPool1D()(conv2)\n",
    "conv3 = Conv1D(filters=128, kernel_size=5, padding='valid', activation=tf.nn.relu)(dropout_emb)\n",
    "pool3 = GlobalMaxPool1D()(conv3)\n",
    "\n",
    "# 3, 4, 5- gram 이후 합치기\n",
    "concat = concatenate([pool1, pool2, pool3])\n",
    "hidden = Dense(128, activation=tf.nn.relu)(concat)\n",
    "dropout_hidden = Dropout(rate=dropout_prob)(hidden)\n",
    "logits = Dense(4, name='logits')(dropout_hidden)\n",
    "predictions = Dense(4, activation=tf.nn.softmax)(logits)\n",
    "\n",
    "# 모델 생성\n",
    "model = Model(inputs=input_layer, outputs=predictions)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(train_ds, validation_data=val_ds, epochs=EPOCH, verbose=1)\n",
    "\n",
    "# 모델 평가(테스트 데이터셋 이용)\n",
    "loss, accuracy = model.evaluate(test_ds, verbose=1)\n",
    "print('Accuracy: %f' % (accuracy * 100))\n",
    "print('loss: %f' % (loss))\n",
    "\n",
    "# 모델 저장\n",
    "model.save('cnn_0305_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0662e3a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T09:33:51.413875Z",
     "start_time": "2022-03-06T09:33:45.592077Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 15)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 15, 128)      2350720     ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 15, 128)      0           ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 13, 128)      49280       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 12, 128)      65664       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 11, 128)      82048       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " global_max_pooling1d (GlobalMa  (None, 128)         0           ['conv1d[0][0]']                 \n",
      " xPooling1D)                                                                                      \n",
      "                                                                                                  \n",
      " global_max_pooling1d_1 (Global  (None, 128)         0           ['conv1d_1[0][0]']               \n",
      " MaxPooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " global_max_pooling1d_2 (Global  (None, 128)         0           ['conv1d_2[0][0]']               \n",
      " MaxPooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 384)          0           ['global_max_pooling1d[0][0]',   \n",
      "                                                                  'global_max_pooling1d_1[0][0]', \n",
      "                                                                  'global_max_pooling1d_2[0][0]'] \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          49280       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 128)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " logits (Dense)                 (None, 4)            516         ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 4)            20          ['logits[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,597,528\n",
      "Trainable params: 2,597,528\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "100/100 - 0s - loss: 0.0231 - accuracy: 0.9915 - 489ms/epoch - 5ms/step\n",
      "단어 시퀀스 :  ['반가반가']\n",
      "단어 인덱스 시퀀스 :  [6339    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "문장 분류(정답) :  0\n",
      "의도 예측 점수 :  [[1.01237014e-16 1.41749491e-17 1.00000000e+00 1.86322566e-14]]\n",
      "의도 예측 클래스 :  [2]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras import preprocessing\n",
    "\n",
    "# 데이터 읽어오기\n",
    "train_file = \"./traindata.csv\"\n",
    "data = pd.read_csv(train_file, delimiter=',')\n",
    "features = data['question'].tolist()\n",
    "labels = data['label'].tolist()\n",
    "\n",
    "# 단어 인덱스 시퀀스 벡터\n",
    "corpus = [preprocessing.text.text_to_word_sequence(text) for text in features]\n",
    "tokenizer = preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "sequences = tokenizer.texts_to_sequences(corpus)\n",
    "MAX_SEQ_LEN = 15 # 단어 시퀀스 벡터 크기\n",
    "padded_seqs = preprocessing.sequence.pad_sequences(sequences, maxlen=MAX_SEQ_LEN, padding='post')\n",
    "\n",
    "# 테스트용 데이터셋 생성\n",
    "ds = tf.data.Dataset.from_tensor_slices((padded_seqs, labels))\n",
    "ds = ds.shuffle(len(features))\n",
    "test_ds = ds.take(2000).batch(20) # 테스트 데이터셋\n",
    "\n",
    "# 감정 분류 CNN 모델 불러오기\n",
    "model = load_model('cnn_0304_model.h5')\n",
    "model.summary()\n",
    "model.evaluate(test_ds, verbose=2)\n",
    "\n",
    "# 테스트용 데이터셋의 10212번째 데이터 출력\n",
    "print(\"단어 시퀀스 : \", corpus[2])\n",
    "print(\"단어 인덱스 시퀀스 : \", padded_seqs[2])\n",
    "print(\"문장 분류(정답) : \", labels[2])\n",
    "\n",
    "# 테스트용 데이터셋의 10212번째 데이터 감정 예측\n",
    "picks = [6111]\n",
    "predict = model.predict(padded_seqs[picks])\n",
    "predict_class = tf.math.argmax(predict, axis=1)\n",
    "print(\"의도 예측 점수 : \", predict)\n",
    "print(\"의도 예측 클래스 : \", predict_class.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1e5897",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T15:35:13.360944Z",
     "start_time": "2022-03-04T15:35:13.347033Z"
    }
   },
   "source": [
    "의도 확인이 끝났으니, 검색모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a49f0c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T08:10:38.845144Z",
     "start_time": "2022-03-06T08:10:38.718526Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         filename  \\\n",
      "0   accuracy_garmin_nuvi_255W_gps   \n",
      "1  bathroom_bestwestern_hotel_sfo   \n",
      "2      battery-life_amazon_kindle   \n",
      "3      battery-life_ipod_nano_8gb   \n",
      "4     battery-life_netbook_1005ha   \n",
      "\n",
      "                                        opinion_text  \n",
      "0                                                ...  \n",
      "1                                                ...  \n",
      "2                                                ...  \n",
      "3                                                ...  \n",
      "4                                                ...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob, os\n",
    "\n",
    "path = r'C:\\Users\\GyeongMinKim\\Desktop\\Univ_Files\\Projects_contests\\Project_AJOU_Chatbot\\_Code\\Drill\\topics'\n",
    "all_files = glob.glob(os.path.join(path,\"*.data\"))\n",
    "filename_list = []\n",
    "opinion_text = []\n",
    "\n",
    "for file_ in all_files:\n",
    "    df = pd.read_table(file_, index_col=None, header=0, encoding='latin1')\n",
    "    filename_ = file_.split('\\\\')[-1]\n",
    "    filename = filename_.split('.')[0]\n",
    "\n",
    "    filename_list.append(filename)\n",
    "    opinion_text.append(df.to_string())\n",
    "\n",
    "document_df = pd.DataFrame({'filename':filename_list, 'opinion_text':opinion_text})\n",
    "print(document_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "456b42a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T04:41:00.445738Z",
     "start_time": "2022-03-09T04:41:00.417091Z"
    }
   },
   "outputs": [],
   "source": [
    "#WordNet is a semantically-oriented dictionary of English included in NLTK.\n",
    "def LemTokens(tokens):\n",
    "    lemmer = nltk.stem.WordNetLemmatizer()\n",
    "    return [lemmer.lemmatize(token) for token in tokens]\n",
    "    # remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "\n",
    "def LemNormalize(text):\n",
    "    remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "52e08806",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T08:41:59.970418Z",
     "start_time": "2022-03-09T08:41:59.957418Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_7652/4073359515.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\GYEONG~1\\AppData\\Local\\Temp/ipykernel_7652/4073359515.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    from sklearn.feature_extraction.text import TfidfVectorizer import Common_Module.CMNLP as CMNLP\u001b[0m\n\u001b[1;37m                                                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer import Common_Module.CMNLP as CMNLP\n",
    "\n",
    "tfodf_vect = TfidfVectorizer(tokenizer=CMNLP.LemNormalize, stop_words='english', ngram_range=(1,2), min_df=0.05, max_df=0.85)\n",
    "feature_vect = tfodf_vect.fit_transform(document_df['opinion_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd3b4eee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T04:41:03.724934Z",
     "start_time": "2022-03-09T04:41:03.696251Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cosine_similarity' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\GYEONG~1\\AppData\\Local\\Temp/ipykernel_8408/319698273.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcosine_sim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfidf_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtfidf_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'코사인 유사도 연산 결과 :'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcosine_sim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cosine_similarity' is not defined"
     ]
    }
   ],
   "source": [
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "print('코사인 유사도 연산 결과 :',cosine_sim.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5912202b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T04:41:05.325196Z",
     "start_time": "2022-03-09T04:41:05.294361Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\GYEONG~1\\AppData\\Local\\Temp/ipykernel_8408/1072188091.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mquestion_to_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'answer'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "question_to_index = dict(zip(data['answer'], data.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8be5c9fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T04:41:06.718021Z",
     "start_time": "2022-03-09T04:41:06.694628Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cosine_sim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\GYEONG~1\\AppData\\Local\\Temp/ipykernel_8408/3101232559.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mget_recommendations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcosine_sim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcosine_sim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;31m# 해당 질문의 인덱스를 받아온다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquestion_to_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mquestion\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# 질문들간 유사도를 가져온다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cosine_sim' is not defined"
     ]
    }
   ],
   "source": [
    "def get_recommendations(question, cosine_sim=cosine_sim):\n",
    "    # 해당 질문의 인덱스를 받아온다.\n",
    "    idx = question_to_index[question]\n",
    "\n",
    "    # 질문들간 유사도를 가져온다.\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    # 유사도에 따라 정렬한다.\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # 가장 유사한 10개의 질문을 받아온다.\n",
    "    sim_scores = sim_scores[1:11]\n",
    "\n",
    "    # 가장 유사한 10개의 질문 인덱스를 얻는다.\n",
    "    expects = [idx[0] for idx in sim_scores]\n",
    "\n",
    "    # 가장 유사한 10개의 질문을 리턴한다.\n",
    "    return data['answer'].iloc[expects]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3feb2eb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T04:41:10.090086Z",
     "start_time": "2022-03-09T04:41:10.075990Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_recommendations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\GYEONG~1\\AppData\\Local\\Temp/ipykernel_8408/2345357188.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_recommendations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'아주 Bb에 이메일 등록 어떻게함???'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'get_recommendations' is not defined"
     ]
    }
   ],
   "source": [
    "get_recommendations('아주 Bb에 이메일 등록 어떻게함???')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852eb78d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T09:01:50.740715Z",
     "start_time": "2022-03-05T09:01:50.727716Z"
    }
   },
   "source": [
    "형태소 분석 확인중"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f70c4aa6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T04:42:07.910741Z",
     "start_time": "2022-03-09T04:42:07.895413Z"
    }
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Komoran\n",
    "\n",
    "class Preprocess:\n",
    "    def __init__(self, userdic = None):\n",
    "        self.komoran = Komoran(userdic=userdic)\n",
    "        self.exclusion_tags = [\n",
    "            'JKS','JKC', 'JKG', 'JKB', 'JKV', 'JKQ', 'JX', 'JC', 'SF', 'SP', 'SS', 'SE', 'SO', 'EP', 'EF', 'EC', 'ETN', 'ETM', 'XSN', 'XSV', 'XSA'\n",
    "            ]\n",
    "        \n",
    "    def pos(self, sentence):\n",
    "        return self.komoran.pos(sentence)\n",
    "    \n",
    "    def get_keywords(self, pos, without_tag = False):\n",
    "        f = lambda x : x in self.exclusion_tags\n",
    "        word_list = []\n",
    "        for p in pos:\n",
    "            if f(p[1]) is False:\n",
    "                word_list.append(p if without_tag is False else p[0])\n",
    "        return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08916e09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T04:42:09.216387Z",
     "start_time": "2022-03-09T04:42:09.187873Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\GYEONG~1\\AppData\\Local\\Temp/ipykernel_8408/2528737175.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtrain_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"./uploadingtestdata.csv\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0msent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'question'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muserdic\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'../utils/user_dic.tsv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "train_file = \"./uploadingtestdata.csv\"\n",
    "data = pd.read_csv(train_file, delimiter=',')\n",
    "sent = data['question'].tolist()\n",
    "\n",
    "p = Preprocess(userdic='../utils/user_dic.tsv')\n",
    "\n",
    "pos = p.pos(sent)\n",
    "\n",
    "ret = p.get_keywords(pos, without_tag = False)\n",
    "print(ret)\n",
    "\n",
    "ret = p.get_keywords(pos, without_tag = True)\n",
    "print(ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9300d17",
   "metadata": {},
   "source": [
    "형태소 분석은 똑바로 작동하네요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fbfc3ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T08:14:01.502598Z",
     "start_time": "2022-03-10T08:13:59.131854Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>소학회 언제까지 가입해야하나요?</td>\n",
       "      <td>상시모집!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>정시생 긱사 발표나신 분 결핵검사서 스캔한거 메일 보내셨나요?</td>\n",
       "      <td>\"격리 해제 후 입사하기 전에 결핵검사 결과 생활관으로 제출 바랍니다. 이메일 주소...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             question  \\\n",
       "0                   소학회 언제까지 가입해야하나요?   \n",
       "1  정시생 긱사 발표나신 분 결핵검사서 스캔한거 메일 보내셨나요?   \n",
       "\n",
       "                                              answer  \n",
       "0                                              상시모집!  \n",
       "1  \"격리 해제 후 입사하기 전에 결핵검사 결과 생활관으로 제출 바랍니다. 이메일 주소...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "data = pd.read_csv('biguploadingtestdata.csv', low_memory=False)\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85fdf5bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T08:14:03.542026Z",
     "start_time": "2022-03-10T08:14:03.479514Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF 행렬의 크기(shape) : (1652, 2750)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(data['answer'])\n",
    "print('TF-IDF 행렬의 크기(shape) :',tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afef1426",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T08:14:04.970621Z",
     "start_time": "2022-03-10T08:14:04.910770Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "코사인 유사도 연산 결과 : (1652, 1652)\n"
     ]
    }
   ],
   "source": [
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "print('코사인 유사도 연산 결과 :',cosine_sim.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f786fafc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T08:14:06.593138Z",
     "start_time": "2022-03-10T08:14:06.578533Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1632\n"
     ]
    }
   ],
   "source": [
    "title_to_index = dict(zip(data['question'], data.index))\n",
    "\n",
    "# 영화 제목 Father of the Bride Part II의 인덱스를 리턴\n",
    "idx = title_to_index['학식 어디로 가서 먹는거아?']\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32473110",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T08:14:09.277109Z",
     "start_time": "2022-03-10T08:14:09.270949Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_recommendations(question, cosine_sim=cosine_sim):\n",
    "    # 선택한 영화의 타이틀로부터 해당 영화의 인덱스를 받아온다.\n",
    "    idx = title_to_index[question]\n",
    "\n",
    "    # 해당 영화와 모든 영화와의 유사도를 가져온다.\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    # 유사도에 따라 영화들을 정렬한다.\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # 가장 유사한 10개의 영화를 받아온다.\n",
    "    sim_scores = sim_scores[:4]\n",
    "\n",
    "    # 가장 유사한 10개의 영화의 인덱스를 얻는다.\n",
    "    movie_indices = [idx[0] for idx in sim_scores]\n",
    "\n",
    "    # 가장 유사한 10개의 영화의 제목을 리턴한다.\n",
    "    return data['answer'].iloc[movie_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c887409",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T08:19:58.592543Z",
     "start_time": "2022-03-10T08:19:58.578444Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24                           3시간 까지 무료, 이후로는 시간당 요금 추가!\n",
       "25                           3시간 까지 무료, 이후로는 시간당 요금 추가!\n",
       "0                                                 상시모집!\n",
       "1     \"격리 해제 후 입사하기 전에 결핵검사 결과 생활관으로 제출 바랍니다. 이메일 주소...\n",
       "Name: answer, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations('기숙사 무인택배함 요금 얼마예요??????????')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01c74ff3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T07:53:21.920656Z",
     "start_time": "2022-03-10T07:53:21.689538Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checked(result=True, original='남제관', checked='남에 관', errors=1, words=OrderedDict([('남에', 4), ('관', 4)]), time=0.09475135803222656)\n"
     ]
    }
   ],
   "source": [
    "from hanspell import spell_checker\n",
    "sent = \"남제관\"\n",
    "spelled_sent = spell_checker.check(sent)\n",
    "print(spelled_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8338de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T08:26:45.287091Z",
     "start_time": "2022-03-09T08:26:45.275087Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9c21878",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T07:37:41.960570Z",
     "start_time": "2022-03-10T07:37:38.568080Z"
    }
   },
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "from konlpy.tag import Komoran\n",
    "\n",
    "komoran = Komoran(userdic='./user_dic.tsv')\n",
    "\n",
    "corpus = [\n",
    "    \"세계 배달 피자 리더 도미노피자가 우리 고구마를 활용한 신메뉴를 출시한다.도미노피자는 오는 2월 1일 국내산 고구마와 4가지 치즈가 어우러진 신메뉴 `우리 고구마 피자`를 출시하고 전 매장에서 판매를 시작한다. 이번에 도미노피자가 내놓은 신메뉴 `우리 고구마 피자`는 까다롭게 엄선한 국내산 고구마를 무스와 큐브 형태로 듬뿍 올리고, 모차렐라, 카망베르, 체더 치즈와 리코타 치즈 소스 등 4가지 치즈와 와규 크럼블을 더한 프리미엄 고구마 피자다.\",\n",
    "    \"피자의 발상지이자 원조라고 할 수 있는 남부의 나폴리식 피자(Pizza Napolitana)는 재료 본연의 맛에 집중하여 뛰어난 식감을 자랑한다. 대표적인 나폴리 피자로는 피자 마리나라(Pizza Marinara)와 피자 마르게리타(Pizza Margherita)가 있다.\",\n",
    "    \"도미노피자가 삼일절을 맞아 '방문포장 1+1' 이벤트를 진행한다. 이번 이벤트는 도미노피자 102개 매장에서 3월 1일 단 하루 동안 방문포장 온라인, 오프라인 주문 시 피자 1판을 더 증정하는 이벤트다. 온라인 주문 시 장바구니에 2판을 담은 후 할인 적용이 가능하며, 동일 가격 또는 낮은 가격의 피자를 고객이 선택하면 무료로 증정한다.\"\n",
    "]\n",
    "\n",
    "def tokenizer(sent):\n",
    "  return komoran.pos(sent)\n",
    "\n",
    "tokenized_corpus = [tokenizer(doc) for doc in corpus]\n",
    "\n",
    "bm25 = BM25Okapi(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44cc1e62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T07:34:47.152639Z",
     "start_time": "2022-03-10T07:34:47.125690Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('세계', 'NNG'): 0.5108256237659907,\n",
       " ('배달', 'NNP'): 0.5108256237659907,\n",
       " ('피자', 'NNP'): 0.06147048382171928,\n",
       " ('리더', 'NNP'): 0.5108256237659907,\n",
       " ('도미노피자', 'NNP'): 0.06147048382171928,\n",
       " ('가', 'JKS'): 0.06147048382171928,\n",
       " ('우리', 'NP'): 0.5108256237659907,\n",
       " ('고구마', 'NNG'): 0.5108256237659907,\n",
       " ('를', 'JKO'): 0.06147048382171928,\n",
       " ('활용', 'NNG'): 0.5108256237659907,\n",
       " ('하', 'XSV'): 0.06147048382171928,\n",
       " ('ㄴ', 'ETM'): 0.06147048382171928,\n",
       " ('신', 'XPN'): 0.5108256237659907,\n",
       " ('메뉴', 'NNP'): 0.5108256237659907,\n",
       " ('출시', 'NNG'): 0.5108256237659907,\n",
       " ('ㄴ다', 'EF'): 0.06147048382171928,\n",
       " ('.', 'SF'): 0.06147048382171928,\n",
       " ('는', 'JX'): 0.06147048382171928,\n",
       " ('오', 'VV'): 0.5108256237659907,\n",
       " ('는', 'ETM'): 0.06147048382171928,\n",
       " ('2월 1일', 'NNP'): 0.5108256237659907,\n",
       " ('국내', 'NNG'): 0.5108256237659907,\n",
       " ('산', 'XSN'): 0.5108256237659907,\n",
       " ('고구마', 'NNP'): 0.5108256237659907,\n",
       " ('와', 'JC'): 0.06147048382171928,\n",
       " ('4', 'SN'): 0.5108256237659907,\n",
       " ('가지', 'NNB'): 0.5108256237659907,\n",
       " ('치즈', 'NNP'): 0.5108256237659907,\n",
       " ('어우러지', 'VV'): 0.5108256237659907,\n",
       " ('`', 'SS'): 0.5108256237659907,\n",
       " ('고', 'EC'): 0.5108256237659907,\n",
       " ('전', 'MM'): 0.5108256237659907,\n",
       " ('매장', 'NNG'): 0.06147048382171928,\n",
       " ('에서', 'JKB'): 0.06147048382171928,\n",
       " ('판매', 'NNG'): 0.5108256237659907,\n",
       " ('시작', 'NNG'): 0.5108256237659907,\n",
       " ('이번', 'NNG'): 0.06147048382171928,\n",
       " ('에', 'JKB'): 0.06147048382171928,\n",
       " ('내놓', 'VV'): 0.5108256237659907,\n",
       " ('은', 'ETM'): 0.06147048382171928,\n",
       " ('까다롭', 'VA'): 0.5108256237659907,\n",
       " ('게', 'EC'): 0.5108256237659907,\n",
       " ('엄선', 'NNG'): 0.5108256237659907,\n",
       " ('무스', 'NNP'): 0.5108256237659907,\n",
       " ('큐브', 'NNP'): 0.5108256237659907,\n",
       " ('형태', 'NNG'): 0.5108256237659907,\n",
       " ('로', 'JKB'): 0.06147048382171928,\n",
       " ('듬뿍', 'MAG'): 0.5108256237659907,\n",
       " ('올리', 'VV'): 0.5108256237659907,\n",
       " (',', 'SP'): 0.06147048382171928,\n",
       " ('모차렐라', 'NNP'): 0.5108256237659907,\n",
       " ('카망베르', 'NNP'): 0.5108256237659907,\n",
       " ('체더 치즈', 'NNP'): 0.5108256237659907,\n",
       " ('리', 'NNB'): 0.5108256237659907,\n",
       " ('코타', 'NNP'): 0.5108256237659907,\n",
       " ('소스', 'NNP'): 0.5108256237659907,\n",
       " ('등', 'NNB'): 0.5108256237659907,\n",
       " ('와', 'NNG'): 0.5108256237659907,\n",
       " ('규', 'NNG'): 0.5108256237659907,\n",
       " ('크럼블을', 'NA'): 0.5108256237659907,\n",
       " ('더하', 'VV'): 0.5108256237659907,\n",
       " ('프리미엄', 'NNP'): 0.5108256237659907,\n",
       " ('다', 'EF'): 0.06147048382171928,\n",
       " ('의', 'JKG'): 0.06147048382171928,\n",
       " ('발상지', 'NNG'): 0.5108256237659907,\n",
       " ('이', 'VCP'): 0.5108256237659907,\n",
       " ('자', 'EC'): 0.5108256237659907,\n",
       " ('원조', 'NNG'): 0.5108256237659907,\n",
       " ('라고', 'EC'): 0.5108256237659907,\n",
       " ('하', 'VV'): 0.5108256237659907,\n",
       " ('ㄹ', 'ETM'): 0.5108256237659907,\n",
       " ('수', 'NNB'): 0.5108256237659907,\n",
       " ('있', 'VV'): 0.5108256237659907,\n",
       " ('남부', 'NNP'): 0.5108256237659907,\n",
       " ('나폴리', 'NNP'): 0.5108256237659907,\n",
       " ('식', 'NNB'): 0.5108256237659907,\n",
       " ('(', 'SS'): 0.5108256237659907,\n",
       " ('Pizza', 'SL'): 0.5108256237659907,\n",
       " ('Napolitana', 'SL'): 0.5108256237659907,\n",
       " (')', 'SS'): 0.5108256237659907,\n",
       " ('재료', 'NNP'): 0.5108256237659907,\n",
       " ('본연', 'NNG'): 0.5108256237659907,\n",
       " ('맛', 'NNG'): 0.5108256237659907,\n",
       " ('집중', 'NNG'): 0.5108256237659907,\n",
       " ('아', 'EC'): 0.06147048382171928,\n",
       " ('뛰어나', 'VA'): 0.5108256237659907,\n",
       " ('식', 'NNG'): 0.5108256237659907,\n",
       " ('감', 'NNG'): 0.5108256237659907,\n",
       " ('을', 'JKO'): 0.06147048382171928,\n",
       " ('자랑', 'NNG'): 0.5108256237659907,\n",
       " ('대표', 'NNG'): 0.5108256237659907,\n",
       " ('적', 'XSN'): 0.5108256237659907,\n",
       " ('마리', 'NNP'): 0.5108256237659907,\n",
       " ('나라', 'NNP'): 0.5108256237659907,\n",
       " ('Marinara', 'SL'): 0.5108256237659907,\n",
       " ('피자 마르게리타', 'NNP'): 0.5108256237659907,\n",
       " ('Margherita', 'SL'): 0.5108256237659907,\n",
       " ('있', 'VX'): 0.5108256237659907,\n",
       " ('삼일절', 'NNG'): 0.5108256237659907,\n",
       " ('맞', 'VV'): 0.5108256237659907,\n",
       " (\"'\", 'SS'): 0.5108256237659907,\n",
       " ('방문', 'NNP'): 0.5108256237659907,\n",
       " ('포장', 'NNP'): 0.5108256237659907,\n",
       " ('1+1', 'NNP'): 0.5108256237659907,\n",
       " ('이벤트', 'NNG'): 0.5108256237659907,\n",
       " ('진행', 'NNG'): 0.5108256237659907,\n",
       " ('이벤트', 'NNP'): 0.5108256237659907,\n",
       " ('102', 'SN'): 0.5108256237659907,\n",
       " ('개', 'NNB'): 0.5108256237659907,\n",
       " ('3월 1일', 'NNP'): 0.5108256237659907,\n",
       " ('단', 'MM'): 0.5108256237659907,\n",
       " ('하루', 'NNG'): 0.5108256237659907,\n",
       " ('동안', 'NNG'): 0.5108256237659907,\n",
       " ('온라인', 'NNG'): 0.5108256237659907,\n",
       " ('오프라인', 'NNP'): 0.5108256237659907,\n",
       " ('주문', 'NNP'): 0.5108256237659907,\n",
       " ('시', 'NNB'): 0.5108256237659907,\n",
       " ('1', 'SN'): 0.5108256237659907,\n",
       " ('판', 'NNB'): 0.5108256237659907,\n",
       " ('더', 'MAG'): 0.5108256237659907,\n",
       " ('증정', 'NNG'): 0.5108256237659907,\n",
       " ('장바구니', 'NNG'): 0.5108256237659907,\n",
       " ('2', 'SN'): 0.5108256237659907,\n",
       " ('담', 'VV'): 0.5108256237659907,\n",
       " ('후', 'NNG'): 0.5108256237659907,\n",
       " ('할인', 'NNG'): 0.5108256237659907,\n",
       " ('적용', 'NNG'): 0.5108256237659907,\n",
       " ('이', 'JKS'): 0.5108256237659907,\n",
       " ('가능', 'XR'): 0.5108256237659907,\n",
       " ('하', 'XSA'): 0.5108256237659907,\n",
       " ('며', 'EC'): 0.5108256237659907,\n",
       " ('동일', 'NNG'): 0.5108256237659907,\n",
       " ('가격', 'NNG'): 0.5108256237659907,\n",
       " ('또는', 'MAJ'): 0.5108256237659907,\n",
       " ('낮', 'VA'): 0.5108256237659907,\n",
       " ('고객', 'NNG'): 0.5108256237659907,\n",
       " ('선택', 'NNG'): 0.5108256237659907,\n",
       " ('면', 'EC'): 0.5108256237659907,\n",
       " ('무료', 'NNG'): 0.5108256237659907}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25.idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03679ce2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T07:37:59.341426Z",
     "start_time": "2022-03-10T07:37:59.322638Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['피자의 발상지이자 원조라고 할 수 있는 남부의 나폴리식 피자(Pizza Napolitana)는 재료 본연의 맛에 집중하여 뛰어난 식감을 자랑한다. 대표적인 나폴리 피자로는 피자 마리나라(Pizza Marinara)와 피자 마르게리타(Pizza Margherita)가 있다.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"나폴리 피자\"\n",
    "tokenized_query = tokenizer(query)\n",
    "bm25.get_top_n(tokenized_query, corpus, n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04fdb2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
