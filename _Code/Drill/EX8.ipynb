{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "458a6dec",
   "metadata": {},
   "source": [
    "8-1 챗봇 전처리 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ec7daa2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T08:58:12.274387Z",
     "start_time": "2022-03-05T08:58:12.191716Z"
    }
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Komoran\n",
    "\n",
    "class Preprocess:\n",
    "    def __init__(self, userdic = None):\n",
    "        self.komoran = Komoran(userdic=userdic)\n",
    "        self.exclusion_tags = [\n",
    "            'JKS','JKC', 'JKG', 'JKB', 'JKV', 'JKQ', 'JX', 'JC', 'SF', 'SP', 'SS', 'SE', 'SO', 'EP', 'EF', 'EC', 'ETN', 'ETM', 'XSN', 'XSV', 'XSA'\n",
    "            ]\n",
    "        \n",
    "    def pos(self, sentence):\n",
    "        return setlf.komoran.pos(sentence)\n",
    "    \n",
    "    def get_keywords(self, pos, without_tag = False):\n",
    "        f = lambda x : x in self.exclusion_tags\n",
    "        word_list = []\n",
    "        for p in pos:\n",
    "            if f(p[1]) is False:\n",
    "                word_list.append(p if without_tag is Fasle else p[0])\n",
    "        return word_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f248545d",
   "metadata": {},
   "source": [
    "8-2 챗봇 전처리 클래스 테스트 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "082fb59b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T08:58:20.287728Z",
     "start_time": "2022-03-05T08:58:20.169729Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'suserdic'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\GYEONG~1\\AppData\\Local\\Temp/ipykernel_11428/1628375362.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"내일 오전 10시에 탕수육 주문하고 싶어\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msuserdic\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'../utils/user_dic.tsv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'suserdic'"
     ]
    }
   ],
   "source": [
    "from utils.preprocess import preprocess\n",
    "\n",
    "sent = \"내일 오전 10시에 탕수육 주문하고 싶어\"\n",
    "\n",
    "p = Preprocess(suserdic='../utils/user_dic.tsv')\n",
    "\n",
    "pos = p.pos(sent)\n",
    "\n",
    "ret = p.get_keywords(pos, without_tag = False)\n",
    "print(ret)\n",
    "\n",
    "ret = p.get_keywords(pos, without_tag = True)\n",
    "printnt(ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b53bd0",
   "metadata": {},
   "source": [
    "8-3 단어 사전 생성 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15637f69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T10:01:28.149916Z",
     "start_time": "2022-03-02T10:01:28.124180Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils.Preprocess'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\GYEONG~1\\AppData\\Local\\Temp/ipykernel_6152/4041583831.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# 챗봇에서 사용하는 사전 파일 생성\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPreprocess\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPreprocess\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'utils.Preprocess'"
     ]
    }
   ],
   "source": [
    "#\n",
    "# 챗봇에서 사용하는 사전 파일 생성\n",
    "#\n",
    "from utils.Preprocess import Preprocess\n",
    "from tensorflow.keras import preprocessing\n",
    "import pickle\n",
    "\n",
    "# 말뭉치 데이터 읽어오기\n",
    "def read_corpus_data(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        data = [line.split('\\t') for line in f.read().splitlines()]\n",
    "    return data\n",
    "\n",
    "\n",
    "# 말뭉치 데이터 가져오기\n",
    "corpus_data = read_corpus_data('./corpus.txt')\n",
    "\n",
    "\n",
    "# 망뭉치 데이터에서 키워드만 추출해서 사전 리스트 생성\n",
    "p = Preprocess(word2index_dic='chatbot_dict.bin',\n",
    "               userdic = '../../utils/user_dic.tsv')\n",
    "dict = []\n",
    "for c in corpus_data:\n",
    "    pos = p.pos(c[1])\n",
    "    for k in pos:\n",
    "        dict.append(k[0])\n",
    "    # keywords = p.get_keywords(pos, without_tag=True)\n",
    "    # for k in keywords:\n",
    "    #     dict.append(k)\n",
    "\n",
    "# 사전에 사용될 word2index 생성\n",
    "# 사전의 첫번 째 인덱스에는 OOV 사용\n",
    "tokenizer = preprocessing.text.Tokenizer(oov_token='OOV')\n",
    "tokenizer.fit_on_texts(dict)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# 사전 파일 생성\n",
    "f = open(\"chatbot_dict.bin\", \"wb\")\n",
    "try:\n",
    "    pickle.dump(word_index, f)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "finally:\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50672420",
   "metadata": {},
   "source": [
    "8-4 단어 사전 테스트 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2880b1b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T10:01:30.792581Z",
     "start_time": "2022-03-02T10:01:30.769596Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils.Preprocess'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\GYEONG~1\\AppData\\Local\\Temp/ipykernel_6152/1587883089.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPreprocess\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPreprocess\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# 단어 사전 불러오기\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../train_tools/dict/chatbot_dict.bin\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'utils.Preprocess'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from utils.Preprocess import Preprocess\n",
    "\n",
    "# 단어 사전 불러오기\n",
    "f = open(\"../train_tools/dict/chatbot_dict.bin\", \"rb\")\n",
    "word_index = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "sent = \"내일 오전 10시에 탕수육 주문하고 싶어 ㅋㅋ\"\n",
    "\n",
    "# 전처리 객체 생성\n",
    "p = Preprocess(userdic='../utils/user_dic.tsv')\n",
    "\n",
    "# 형태소분석기 실행\n",
    "pos = p.pos(sent)\n",
    "\n",
    "# 품사 태그 없이 키워드 출력\n",
    "keywords = p.get_keywords(pos, without_tag=True)\n",
    "for word in keywords:\n",
    "    try:\n",
    "        print(word, word_index[word])\n",
    "    except KeyError:\n",
    "        # 해당 단어가 사전에 없는 경우, OOV 처리\n",
    "        print(word, word_index['OOV'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2dcb2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T07:08:17.978624Z",
     "start_time": "2022-02-28T07:08:17.959701Z"
    }
   },
   "source": [
    "8-5 전처리 클래스에 단어 인덱스 시퀀스 변환 메서드 추가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd034e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f1e1a8d",
   "metadata": {},
   "source": [
    "8-6 글로벌 파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e7bc75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0daffd4",
   "metadata": {},
   "source": [
    "8-7 챗봇 엔진 의도 분류 모델 (학습을 통해 모델을 파일로 저장)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d208c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 모듈 임포트\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, Dropout, Conv1D, GlobalMaxPool1D, concatenate\n",
    "\n",
    "\n",
    "# 데이터 읽어오기\n",
    "train_file = \"total_train_data.csv\"\n",
    "data = pd.read_csv(train_file, delimiter=',')\n",
    "queries = data['query'].tolist()\n",
    "intents = data['intent'].tolist()\n",
    "\n",
    "from utils.Preprocess import Preprocess\n",
    "p = Preprocess(word2index_dic='../../train_tools/dict/chatbot_dict.bin',\n",
    "               userdic='../../utils/user_dic.tsv')\n",
    "\n",
    "# 단어 시퀀스 생성\n",
    "sequences = []\n",
    "for sentence in queries:\n",
    "    pos = p.pos(sentence)\n",
    "    keywords = p.get_keywords(pos, without_tag=True)\n",
    "    seq = p.get_wordidx_sequence(keywords)\n",
    "    sequences.append(seq)\n",
    "\n",
    "\n",
    "# 단어 인덱스 시퀀스 벡터 ○2\n",
    "# 단어 시퀀스 벡터 크기\n",
    "from config.GlobalParams import MAX_SEQ_LEN\n",
    "padded_seqs = preprocessing.sequence.pad_sequences(sequences, maxlen=MAX_SEQ_LEN, padding='post')\n",
    "\n",
    "# (105658, 15)\n",
    "print(padded_seqs.shape)\n",
    "print(len(intents)) #105658\n",
    "\n",
    "# 학습용, 검증용, 테스트용 데이터셋 생성 ○3\n",
    "# 학습셋:검증셋:테스트셋 = 7:2:1\n",
    "ds = tf.data.Dataset.from_tensor_slices((padded_seqs, intents))\n",
    "ds = ds.shuffle(len(queries))\n",
    "\n",
    "train_size = int(len(padded_seqs) * 0.7)\n",
    "val_size = int(len(padded_seqs) * 0.2)\n",
    "test_size = int(len(padded_seqs) * 0.1)\n",
    "\n",
    "train_ds = ds.take(train_size).batch(20)\n",
    "val_ds = ds.skip(train_size).take(val_size).batch(20)\n",
    "test_ds = ds.skip(train_size + val_size).take(test_size).batch(20)\n",
    "\n",
    "# 하이퍼 파라미터 설정\n",
    "dropout_prob = 0.5\n",
    "EMB_SIZE = 128\n",
    "EPOCH = 5\n",
    "VOCAB_SIZE = len(p.word_index) + 1 #전체 단어 개수\n",
    "\n",
    "\n",
    "# CNN 모델 정의  ○4\n",
    "input_layer = Input(shape=(MAX_SEQ_LEN,))\n",
    "embedding_layer = Embedding(VOCAB_SIZE, EMB_SIZE, input_length=MAX_SEQ_LEN)(input_layer)\n",
    "dropout_emb = Dropout(rate=dropout_prob)(embedding_layer)\n",
    "\n",
    "conv1 = Conv1D(\n",
    "    filters=128,\n",
    "    kernel_size=3,\n",
    "    padding='valid',\n",
    "    activation=tf.nn.relu)(dropout_emb)\n",
    "pool1 = GlobalMaxPool1D()(conv1)\n",
    "\n",
    "conv2 = Conv1D(\n",
    "    filters=128,\n",
    "    kernel_size=4,\n",
    "    padding='valid',\n",
    "    activation=tf.nn.relu)(dropout_emb)\n",
    "pool2 = GlobalMaxPool1D()(conv2)\n",
    "\n",
    "conv3 = Conv1D(\n",
    "    filters=128,\n",
    "    kernel_size=5,\n",
    "    padding='valid',\n",
    "    activation=tf.nn.relu)(dropout_emb)\n",
    "pool3 = GlobalMaxPool1D()(conv3)\n",
    "\n",
    "# 3,4,5gram 이후 합치기\n",
    "concat = concatenate([pool1, pool2, pool3])\n",
    "\n",
    "hidden = Dense(128, activation=tf.nn.relu)(concat)\n",
    "dropout_hidden = Dropout(rate=dropout_prob)(hidden)\n",
    "logits = Dense(5, name='logits')(dropout_hidden)\n",
    "predictions = Dense(5, activation=tf.nn.softmax)(logits)\n",
    "\n",
    "\n",
    "# 모델 생성  ○5\n",
    "model = Model(inputs=input_layer, outputs=predictions)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# 모델 학습 ○6\n",
    "model.fit(train_ds, validation_data=val_ds, epochs=EPOCH, verbose=1)\n",
    "\n",
    "\n",
    "# 모델 평가(테스트 데이터 셋 이용) ○7\n",
    "loss, accuracy = model.evaluate(test_ds, verbose=1)\n",
    "print('Accuracy: %f' % (accuracy * 100))\n",
    "print('loss: %f' % (loss))\n",
    "\n",
    "\n",
    "# 모델 저장  ○8\n",
    "model.save('intent_model.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a49b6b5",
   "metadata": {},
   "source": [
    "8-8 챗봇 엔진 의도 분류 모델 모듈 (8-7에서 학습한 모델 파일을 활용해 예측함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "998e25b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T07:15:21.384572Z",
     "start_time": "2022-02-28T07:15:18.406802Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras import preprocessing\n",
    "\n",
    "\n",
    "# 의도 분류 모델 모듈\n",
    "class IntentModel:\n",
    "    def __init__(self, model_name, proprocess):\n",
    "\n",
    "        # 의도 클래스 별 레이블\n",
    "        self.labels = {0: \"인사\", 1: \"욕설\", 2: \"주문\", 3: \"예약\", 4: \"기타\"}\n",
    "\n",
    "        # 의도 분류 모델 불러오기\n",
    "        self.model = load_model(model_name)\n",
    "\n",
    "        # 챗봇 Preprocess 객체\n",
    "        self.p = proprocess\n",
    "\n",
    "\n",
    "    # 의도 클래스 예측\n",
    "    def predict_class(self, query):\n",
    "        # 형태소 분석\n",
    "        pos = self.p.pos(query)\n",
    "\n",
    "        # 문장내 키워드 추출(불용어 제거)\n",
    "        keywords = self.p.get_keywords(pos, without_tag=True)\n",
    "        sequences = [self.p.get_wordidx_sequence(keywords)]\n",
    "\n",
    "        # 단어 시퀀스 벡터 크기\n",
    "        from config.GlobalParams import MAX_SEQ_LEN\n",
    "\n",
    "        # 패딩처리\n",
    "        padded_seqs = preprocessing.sequence.pad_sequences(sequences, maxlen=MAX_SEQ_LEN, padding='post')\n",
    "\n",
    "        predict = self.model.predict(padded_seqs)\n",
    "        predict_class = tf.math.argmax(predict, axis=1)\n",
    "        return predict_class.numpy()[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2110c6a",
   "metadata": {},
   "source": [
    "8-9 intentModel 객체 사용 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63fc02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.Preprocess import Preprocess\n",
    "from models.intent.IntentModel import IntentModel\n",
    "\n",
    "p = Preprocess(word2index_dic='../train_tools/dict/chatbot_dict.bin',\n",
    "               userdic='../utils/user_dic.tsv')\n",
    "\n",
    "intent = IntentModel(model_name='../models/intent/intent_model.h5', proprocess=p)\n",
    "query = \"오늘 탕수육 주문 가능한가요?\"\n",
    "predict = intent.predict_class(query)\n",
    "predict_label = intent.labels[predict]\n",
    "\n",
    "print(query)\n",
    "print(\"의도 예측 클래스 : \", predict)\n",
    "print(\"의도 예측 레이블 : \", predict_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb05b53c",
   "metadata": {},
   "source": [
    "8-10 챗봇 엔진 NER 모델 (학습을 통해 모델을 생성하고 파일로 저장함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e030253d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T10:02:08.457408Z",
     "start_time": "2022-03-02T10:01:59.777270Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils.Preprocess'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\GYEONG~1\\AppData\\Local\\Temp/ipykernel_6152/412824809.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPreprocess\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPreprocess\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# 학습 파일 불러오기\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'utils.Preprocess'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from utils.Preprocess import Preprocess\n",
    "\n",
    "# 학습 파일 불러오기\n",
    "def read_file(file_name):\n",
    "    sents = []\n",
    "    with open(file_name, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        for idx, l in enumerate(lines):\n",
    "            if l[0] == ';' and lines[idx + 1][0] == '$':\n",
    "                this_sent = []\n",
    "            elif l[0] == '$' and lines[idx - 1][0] == ';':\n",
    "                continue\n",
    "            elif l[0] == '\\n':\n",
    "                sents.append(this_sent)\n",
    "            else:\n",
    "                this_sent.append(tuple(l.split()))\n",
    "    return sents\n",
    "\n",
    "p = Preprocess(word2index_dic='../../train_tools/dict/chatbot_dict.bin',\n",
    "               userdic='../../utils/user_dic.tsv')\n",
    "\n",
    "# 학습용 말뭉치 데이터를 불러옴\n",
    "corpus = read_file('ner_train.txt')\n",
    "\n",
    "# 말뭉치 데이터에서 단어와 BIO 태그만 불러와 학습용 데이터셋 생성\n",
    "sentences, tags = [], []\n",
    "for t in corpus:\n",
    "    tagged_sentence = []\n",
    "    sentence, bio_tag = [], []\n",
    "    for w in t:\n",
    "        tagged_sentence.append((w[1], w[3]))\n",
    "        sentence.append(w[1])\n",
    "        bio_tag.append(w[3])\n",
    "    \n",
    "    sentences.append(sentence)\n",
    "    tags.append(bio_tag)\n",
    "\n",
    "\n",
    "print(\"샘플 크기 : \\n\", len(sentences))\n",
    "print(\"0번 째 샘플 단어 시퀀스 : \\n\", sentences[0])\n",
    "print(\"0번 째 샘플 bio 태그 : \\n\", tags[0])\n",
    "print(\"샘플 단어 시퀀스 최대 길이 :\", max(len(l) for l in sentences))\n",
    "print(\"샘플 단어 시퀀스 평균 길이 :\", (sum(map(len, sentences))/len(sentences)))\n",
    "\n",
    "# 토크나이저 정의\n",
    "tag_tokenizer = preprocessing.text.Tokenizer(lower=False) # 태그 정보는 lower=False 소문자로 변환하지 않는다.\n",
    "tag_tokenizer.fit_on_texts(tags)\n",
    "\n",
    "# 단어사전 및 태그 사전 크기\n",
    "vocab_size = len(p.word_index) + 1\n",
    "tag_size = len(tag_tokenizer.word_index) + 1\n",
    "print(\"BIO 태그 사전 크기 :\", tag_size)\n",
    "print(\"단어 사전 크기 :\", vocab_size)\n",
    "\n",
    "# 학습용 단어 시퀀스 생성\n",
    "x_train = [p.get_wordidx_sequence(sent) for sent in sentences]\n",
    "y_train = tag_tokenizer.texts_to_sequences(tags)\n",
    "\n",
    "index_to_ner = tag_tokenizer.index_word # 시퀀스 인덱스를 NER로 변환 하기 위해 사용\n",
    "index_to_ner[0] = 'PAD'\n",
    "\n",
    "# 시퀀스 패딩 처리\n",
    "max_len = 40\n",
    "x_train = preprocessing.sequence.pad_sequences(x_train, padding='post', maxlen=max_len)\n",
    "y_train = preprocessing.sequence.pad_sequences(y_train, padding='post', maxlen=max_len)\n",
    "\n",
    "# 학습 데이터와 테스트 데이터를 8:2의 비율로 분리\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train,\n",
    "                                                    test_size=.2,\n",
    "                                                    random_state=1234)\n",
    "\n",
    "# 출력 데이터를 one-hot encoding\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=tag_size)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=tag_size)\n",
    "\n",
    "print(\"학습 샘플 시퀀스 형상 : \", x_train.shape)\n",
    "print(\"학습 샘플 레이블 형상 : \", y_train.shape)\n",
    "print(\"테스트 샘플 시퀀스 형상 : \", x_test.shape)\n",
    "print(\"테스트 샘플 레이블 형상 : \", y_test.shape)\n",
    "\n",
    "\n",
    "# 모델 정의 (Bi-LSTM)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=30, input_length=max_len, mask_zero=True))\n",
    "model.add(Bidirectional(LSTM(200, return_sequences=True, dropout=0.50, recurrent_dropout=0.25)))\n",
    "model.add(TimeDistributed(Dense(tag_size, activation='softmax')))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(0.01), metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=128, epochs=10)\n",
    "\n",
    "print(\"평가 결과 : \", model.evaluate(x_test, y_test)[1])\n",
    "model.save('ner_model.h5')\n",
    "\n",
    "\n",
    "# 시퀀스를 NER 태그로 변환\n",
    "def sequences_to_tag(sequences):  # 예측값을 index_to_ner를 사용하여 태깅 정보로 변경하는 함수.\n",
    "    result = []\n",
    "    for sequence in sequences:  # 전체 시퀀스로부터 시퀀스를 하나씩 꺼낸다.\n",
    "        temp = []\n",
    "        for pred in sequence:  # 시퀀스로부터 예측값을 하나씩 꺼낸다.\n",
    "            pred_index = np.argmax(pred)  # 예를 들어 [0, 0, 1, 0 ,0]라면 1의 인덱스인 2를 리턴한다.\n",
    "            temp.append(index_to_ner[pred_index].replace(\"PAD\", \"O\"))  # 'PAD'는 'O'로 변경\n",
    "        result.append(temp)\n",
    "    return result\n",
    "\n",
    "\n",
    "# f1 스코어 계산을 위해 사용\n",
    "from seqeval.metrics import f1_score, classification_report\n",
    "\n",
    "# 테스트 데이터셋의 NER 예측\n",
    "y_predicted = model.predict(x_test)\n",
    "pred_tags = sequences_to_tag(y_predicted) # 예측된 NER\n",
    "test_tags = sequences_to_tag(y_test)    # 실제 NER\n",
    "\n",
    "# F1 평가 결과\n",
    "print(classification_report(test_tags, pred_tags))\n",
    "print(\"F1-score: {:.1%}\".format(f1_score(test_tags, pred_tags)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5890d28e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T07:22:10.409782Z",
     "start_time": "2022-02-28T07:22:10.392175Z"
    }
   },
   "source": [
    "8-11 챗봇 엔진 NER 모델 모듈 (8-10에서 만든 모델을 통해 문장 내부의 개체명 인식)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec040fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras import preprocessing\n",
    "\n",
    "\n",
    "# 개체명 인식 모델 모듈\n",
    "class NerModel:\n",
    "    def __init__(self, model_name, proprocess):\n",
    "\n",
    "        # BIO 태그 클래스 별 레이블\n",
    "        self.index_to_ner = {1: 'O', 2: 'B_DT', 3: 'B_FOOD', 4: 'I', 5: 'B_OG', 6: 'B_PS', 7: 'B_LC', 8: 'NNP', 9: 'B_TI', 0: 'PAD'}\n",
    "\n",
    "        # 의도 분류 모델 불러오기\n",
    "        self.model = load_model(model_name)\n",
    "\n",
    "        # 챗봇 Preprocess 객체\n",
    "        self.p = proprocess\n",
    "\n",
    "\n",
    "    # 개체명 클래스 예측\n",
    "    def predict(self, query):\n",
    "        # 형태소 분석\n",
    "        pos = self.p.pos(query)\n",
    "\n",
    "        # 문장내 키워드 추출(불용어 제거)\n",
    "        keywords = self.p.get_keywords(pos, without_tag=True)\n",
    "        sequences = [self.p.get_wordidx_sequence(keywords)]\n",
    "\n",
    "        # 패딩처리\n",
    "        max_len = 40\n",
    "        padded_seqs = preprocessing.sequence.pad_sequences(sequences, padding=\"post\", value=0, maxlen=max_len)\n",
    "\n",
    "        predict = self.model.predict(np.array([padded_seqs[0]]))\n",
    "        predict_class = tf.math.argmax(predict, axis=-1)\n",
    "\n",
    "        tags = [self.index_to_ner[i] for i in predict_class.numpy()[0]]\n",
    "        return list(zip(keywords, tags))\n",
    "\n",
    "    def predict_tags(self, query):\n",
    "        # 형태소 분석\n",
    "        pos = self.p.pos(query)\n",
    "\n",
    "        # 문장내 키워드 추출(불용어 제거)\n",
    "        keywords = self.p.get_keywords(pos, without_tag=True)\n",
    "        sequences = [self.p.get_wordidx_sequence(keywords)]\n",
    "\n",
    "        # 패딩처리\n",
    "        max_len = 40\n",
    "        padded_seqs = preprocessing.sequence.pad_sequences(sequences, padding=\"post\", value=0, maxlen=max_len)\n",
    "\n",
    "        predict = self.model.predict(np.array([padded_seqs[0]]))\n",
    "        predict_class = tf.math.argmax(predict, axis=-1)\n",
    "\n",
    "        tags = []\n",
    "        for tag_idx in predict_class.numpy()[0]:\n",
    "            if tag_idx == 1: continue\n",
    "            tags.append(self.index_to_ner[tag_idx])\n",
    "\n",
    "        if len(tags) == 0: return None\n",
    "        return tags\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085513e1",
   "metadata": {},
   "source": [
    "8-12 NerModel 객체 사용(새로운 문장으로부터 개체명 인식)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799e783a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.Preprocess import Preprocess\n",
    "from models.ner.NerModel import NerModel\n",
    "\n",
    "p = Preprocess(word2index_dic='../train_tools/dict/chatbot_dict.bin',\n",
    "               userdic='../utils/user_dic.tsv')\n",
    "\n",
    "\n",
    "ner = NerModel(model_name='../models/ner/ner_model.h5', proprocess=p)\n",
    "query = '오늘 오전 13시 2분에 탕수육 주문 하고 싶어요'\n",
    "predicts = ner.predict(query)\n",
    "tags = ner.predict_tags(query)\n",
    "print(predicts)\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a1b174",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T07:27:11.909659Z",
     "start_time": "2022-02-28T07:27:11.894531Z"
    }
   },
   "source": [
    "8-13 데이터 베이스 제어 모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e108b85e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T08:25:47.853283Z",
     "start_time": "2022-03-06T08:25:47.802919Z"
    }
   },
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import pymysql.cursors\n",
    "import logging\n",
    "\n",
    "\n",
    "class Database:\n",
    "    '''\n",
    "    database 제어\n",
    "    '''\n",
    "\n",
    "    def __init__(self, host, user, password, db_name, charset='utf8'):\n",
    "        self.host = host\n",
    "        self.user = user\n",
    "        self.password = password\n",
    "        self.charset = charset\n",
    "        self.db_name = db_name\n",
    "        self.conn = None\n",
    "\n",
    "    # DB 연결\n",
    "    def connect(self):\n",
    "        if self.conn != None:\n",
    "            return\n",
    "\n",
    "        self.conn = pymysql.connect(\n",
    "            host='127.0.0.1',\n",
    "            user='root',\n",
    "            passwd='kgm10047320!',\n",
    "            db='test_0306',\n",
    "            charset='utf8'\n",
    "        )\n",
    "\n",
    "    # DB 연결 닫기\n",
    "    def close(self):\n",
    "        if self.conn is None:\n",
    "            return\n",
    "\n",
    "        if not self.conn.open:\n",
    "            self.conn = None\n",
    "            return\n",
    "        self.conn.close()\n",
    "        self.conn = None\n",
    "\n",
    "    # SQL 구문 실행\n",
    "    def execute(self, sql):\n",
    "        last_row_id = -1\n",
    "        try:\n",
    "            with self.conn.cursor() as cursor:\n",
    "                cursor.execute(sql)\n",
    "            self.conn.commit()\n",
    "            last_row_id = cursor.lastrowid\n",
    "            # logging.debug(\"excute last_row_id : %d\", last_row_id)\n",
    "        except Exception as ex:\n",
    "            logging.error(ex)\n",
    "\n",
    "        finally:\n",
    "            return last_row_id\n",
    "\n",
    "    # SELECT 구문 실행 후, 단 1개의 데이터 ROW만 불러옴\n",
    "    def select_one(self, sql):\n",
    "        result = None\n",
    "\n",
    "        try:\n",
    "            with self.conn.cursor(pymysql.cursors.DictCursor) as cursor:\n",
    "                cursor.execute(sql)\n",
    "                result = cursor.fetchone()\n",
    "        except Exception as ex:\n",
    "            logging.error(ex)\n",
    "\n",
    "        finally:\n",
    "            return result\n",
    "\n",
    "    # SELECT 구문 실행 후, 전체 데이터 ROW만 불러옴\n",
    "    def select_all(self, sql):\n",
    "        result = None\n",
    "\n",
    "        try:\n",
    "            with self.conn.cursor(pymysql.cursors.DictCursor) as cursor:\n",
    "                cursor.execute(sql)\n",
    "                result = cursor.fetchall()\n",
    "        except Exception as ex:\n",
    "            logging.error(ex)\n",
    "\n",
    "        finally:\n",
    "            return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5701feee",
   "metadata": {},
   "source": [
    "8-14 챗봇 답변 검색 모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60dda628",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T08:25:56.910870Z",
     "start_time": "2022-03-06T08:25:56.893869Z"
    }
   },
   "outputs": [],
   "source": [
    "class FindAnswer:\n",
    "    def __init__(self, db):\n",
    "        self.db = db\n",
    "\n",
    "    # 검색 쿼리 생성\n",
    "    def _make_query(self, intent_name, ner_tags):\n",
    "        sql = \"select * from chatbot_train_data\"\n",
    "        if intent_name != None and ner_tags == None:\n",
    "            sql = sql + \" where intent='{}' \".format(intent_name)\n",
    "\n",
    "        elif intent_name != None and ner_tags != None:\n",
    "            where = ' where intent=\"%s\" ' % intent_name\n",
    "            if (len(ner_tags) > 0):\n",
    "                where += 'and ('\n",
    "                for ne in ner_tags:\n",
    "                    where += \" ner like '%{}%' or \".format(ne)\n",
    "                where = where[:-3] + ')'\n",
    "            sql = sql + where\n",
    "\n",
    "        # 동일한 답변이 2개 이상인 경우, 랜덤으로 선택\n",
    "        sql = sql + \" order by rand() limit 1\"\n",
    "        return sql\n",
    "\n",
    "    # 답변 검색\n",
    "    def search(self, intent_name, ner_tags):\n",
    "        # 의도명, 개체명으로 답변 검색\n",
    "        sql = self._make_query(intent_name, ner_tags)\n",
    "        answer = self.db.select_one(sql)\n",
    "\n",
    "        # 검색되는 답변이 없으면 의도명만 검색\n",
    "        if answer is None:\n",
    "            sql = self._make_query(intent_name, None)\n",
    "            answer = self.db.select_one(sql)\n",
    "\n",
    "        return (answer['answer'], answer['answer_image'])\n",
    "\n",
    "    # NER 태그를 실제 입력된 단어로 변환\n",
    "    def tag_to_word(self, ner_predicts, answer):\n",
    "        for word, tag in ner_predicts:\n",
    "\n",
    "            # 변환해야하는 태그가 있는 경우 추가\n",
    "            if tag == 'B_FOOD' or tag == 'B_DT' or tag == 'B_TI':\n",
    "                answer = answer.replace(tag, word)\n",
    "\n",
    "        answer = answer.replace('{', '')\n",
    "        answer = answer.replace('}', '')\n",
    "        return answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398add86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T07:29:53.269413Z",
     "start_time": "2022-02-28T07:29:53.259393Z"
    }
   },
   "source": [
    "8-15 챗봇 엔진 동작 (위에서 만든 코드들의 종합버전. query로 입력된 문장으로부터, 분류/인식/검색/출력)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee899f4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T07:33:53.802524Z",
     "start_time": "2022-02-28T07:33:53.481505Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'config.DatabaseConfig'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\GYEONG~1\\AppData\\Local\\Temp/ipykernel_13552/1638371400.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDatabaseConfig\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDatabase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDatabase\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPreprocess\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPreprocess\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# 전처리 객체 생성\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'config.DatabaseConfig'"
     ]
    }
   ],
   "source": [
    "from config.DatabaseConfig import *\n",
    "from utils.Database import Database\n",
    "from utils.Preprocess import Preprocess\n",
    "\n",
    "# 전처리 객체 생성\n",
    "p = Preprocess(word2index_dic='../train_tools/dict/chatbot_dict.bin',\n",
    "               userdic='../utils/user_dic.tsv')\n",
    "\n",
    "# 질문/답변 학습 디비 연결 객체 생성\n",
    "db = Database(\n",
    "    host=DB_HOST, user=DB_USER, password=DB_PASSWORD, db_name=DB_NAME\n",
    ")\n",
    "db.connect()    # 디비 연결\n",
    "\n",
    "# 원문\n",
    "# query = \"오전에 탕수육 10개 주문합니다\"\n",
    "# query = \"화자의 질문 의도를 파악합니다.\"\n",
    "# query = \"안녕하세요\"\n",
    "query = \"자장면 주문할게요\"\n",
    "\n",
    "# 의도 파악\n",
    "from models.intent.IntentModel import IntentModel\n",
    "intent = IntentModel(model_name='../models/intent/intent_model.h5', proprocess=p)\n",
    "predict = intent.predict_class(query)\n",
    "intent_name = intent.labels[predict]\n",
    "\n",
    "# 개체명 인식\n",
    "from models.ner.NerModel import NerModel\n",
    "ner = NerModel(model_name='../models/ner/ner_model.h5', proprocess=p)\n",
    "predicts = ner.predict(query)\n",
    "ner_tags = ner.predict_tags(query)\n",
    "\n",
    "print(\"질문 : \", query)\n",
    "print(\"=\" * 100)\n",
    "print(\"의도 파악 : \", intent_name)\n",
    "print(\"개체명 인식 : \", predicts)\n",
    "print(\"답변 검색에 필요한 NER 태그 : \", ner_tags)\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# 답변 검색\n",
    "from utils.FindAnswer import FindAnswer\n",
    "\n",
    "try:\n",
    "    f = FindAnswer(db)\n",
    "    answer_text, answer_image = f.search(intent_name, ner_tags)\n",
    "    answer = f.tag_to_word(predicts, answer_text)\n",
    "except:\n",
    "    answer = \"죄송해요 무슨 말인지 모르겠어요\"\n",
    "\n",
    "print(\"답변 : \", answer)\n",
    "\n",
    "db.close() # 디비 연결 끊음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2593197",
   "metadata": {},
   "source": [
    "8-16 챗봇 서버 모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e69f424",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T07:34:20.679490Z",
     "start_time": "2022-02-28T07:34:20.675491Z"
    }
   },
   "outputs": [],
   "source": [
    "import socket\n",
    "\n",
    "class BotServer:\n",
    "    def __init__(self, srv_port, listen_num):\n",
    "        self.port = srv_port\n",
    "        self.listen = listen_num\n",
    "        self.mySock = None\n",
    "\n",
    "    # sock 생성\n",
    "    def create_sock(self):\n",
    "        self.mySock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "        self.mySock.bind((\"0.0.0.0\", int(self.port)))\n",
    "        self.mySock.listen(int(self.listen))\n",
    "        return self.mySock\n",
    "\n",
    "    # client 대기\n",
    "    def ready_for_client(self):\n",
    "        return self.mySock.accept()\n",
    "\n",
    "    # sock 반환\n",
    "    def get_sock(self):\n",
    "        return self.mySock\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3bf8cb",
   "metadata": {},
   "source": [
    "8-17 챗봇 엔진 서버 메인 프로그램"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6674773e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T07:35:40.528608Z",
     "start_time": "2022-02-28T07:35:40.497607Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'config.DatabaseConfig'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\GYEONG~1\\AppData\\Local\\Temp/ipykernel_13552/1117522631.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDatabaseConfig\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDatabase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDatabase\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBotServer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBotServer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'config.DatabaseConfig'"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import json\n",
    "\n",
    "from config.DatabaseConfig import *\n",
    "from utils.Database import Database\n",
    "from utils.BotServer import BotServer\n",
    "from utils.Preprocess import Preprocess\n",
    "from models.intent.IntentModel import IntentModel\n",
    "from models.ner.NerModel import NerModel\n",
    "from utils.FindAnswer import FindAnswer\n",
    "\n",
    "\n",
    "# 전처리 객체 생성\n",
    "p = Preprocess(word2index_dic='train_tools/dict/chatbot_dict.bin',\n",
    "               userdic='utils/user_dic.tsv')\n",
    "\n",
    "# 의도 파악 모델\n",
    "intent = IntentModel(model_name='models/intent/intent_model.h5', proprocess=p)\n",
    "\n",
    "# 개체명 인식 모델\n",
    "ner = NerModel(model_name='models/ner/ner_model.h5', proprocess=p)\n",
    "\n",
    "\n",
    "def to_client(conn, addr, params):\n",
    "    db = params['db']\n",
    "\n",
    "    try:\n",
    "        db.connect()  # 디비 연결\n",
    "\n",
    "        # 데이터 수신\n",
    "        read = conn.recv(2048)  # 수신 데이터가 있을 때 까지 블로킹\n",
    "        print('===========================')\n",
    "        print('Connection from: %s' % str(addr))\n",
    "\n",
    "        if read is None or not read:\n",
    "            # 클라이언트 연결이 끊어지거나, 오류가 있는 경우\n",
    "            print('클라이언트 연결 끊어짐')\n",
    "            exit(0)\n",
    "\n",
    "\n",
    "        # json 데이터로 변환\n",
    "        recv_json_data = json.loads(read.decode())\n",
    "        print(\"데이터 수신 : \", recv_json_data)\n",
    "        query = recv_json_data['Query']\n",
    "\n",
    "        # 의도 파악\n",
    "        intent_predict = intent.predict_class(query)\n",
    "        intent_name = intent.labels[intent_predict]\n",
    "\n",
    "        # 개체명 파악\n",
    "        ner_predicts = ner.predict(query)\n",
    "        ner_tags = ner.predict_tags(query)\n",
    "\n",
    "\n",
    "        # 답변 검색\n",
    "        try:\n",
    "            f = FindAnswer(db)\n",
    "            answer_text, answer_image = f.search(intent_name, ner_tags)\n",
    "            answer = f.tag_to_word(ner_predicts, answer_text)\n",
    "\n",
    "        except:\n",
    "            answer = \"죄송해요 무슨 말인지 모르겠어요. 조금 더 공부 할게요.\"\n",
    "            answer_image = None\n",
    "\n",
    "        send_json_data_str = {\n",
    "            \"Query\" : query,\n",
    "            \"Answer\": answer,\n",
    "            \"AnswerImageUrl\" : answer_image,\n",
    "            \"Intent\": intent_name,\n",
    "            \"NER\": str(ner_predicts)\n",
    "        }\n",
    "        message = json.dumps(send_json_data_str)\n",
    "        conn.send(message.encode())\n",
    "\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "\n",
    "    finally:\n",
    "        if db is not None: # db 연결 끊기\n",
    "            db.close()\n",
    "        conn.close()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # 질문/답변 학습 디비 연결 객체 생성\n",
    "    db = Database(\n",
    "        host=DB_HOST, user=DB_USER, password=DB_PASSWORD, db_name=DB_NAME\n",
    "    )\n",
    "    print(\"DB 접속\")\n",
    "\n",
    "    port = 5050\n",
    "    listen = 100\n",
    "\n",
    "    # 봇 서버 동작\n",
    "    bot = BotServer(port, listen)\n",
    "    bot.create_sock()\n",
    "    print(\"bot start\")\n",
    "\n",
    "    while True:\n",
    "        conn, addr = bot.ready_for_client()\n",
    "        params = {\n",
    "            \"db\": db\n",
    "        }\n",
    "\n",
    "        client = threading.Thread(target=to_client, args=(\n",
    "            conn,\n",
    "            addr,\n",
    "            params\n",
    "        ))\n",
    "        client.start()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7b998d",
   "metadata": {},
   "source": [
    "8-18 챗봇 테스트 클라이언트 프로그램"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd3cd327",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-06T08:27:06.348129Z",
     "start_time": "2022-03-06T08:26:59.910148Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문 : \n",
      "이게된다고?\n",
      "----------------------------------------\n"
     ]
    },
    {
     "ename": "ConnectionRefusedError",
     "evalue": "[WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\GYEONG~1\\AppData\\Local\\Temp/ipykernel_9636/908849517.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m# 챗봇 엔진 서버 연결\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mmySocket\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mmySocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;31m# 챗봇 엔진 질의 요청\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectionRefusedError\u001b[0m: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "import json\n",
    "\n",
    "# 챗봇 엔진 서버 접속 정보\n",
    "host = \"127.0.0.1\"  # 챗봇 엔진 서버 IP 주소\n",
    "port = 5050  # 챗봇 엔진 서버 통신 포트\n",
    "\n",
    "# 클라이언트 프로그램 시작\n",
    "while True:\n",
    "    print(\"질문 : \")\n",
    "    query = input()  # 질문 입력\n",
    "    if(query == \"exit\"):\n",
    "        exit(0)\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    # 챗봇 엔진 서버 연결\n",
    "    mySocket = socket.socket()\n",
    "    mySocket.connect((host, port))\n",
    "\n",
    "    # 챗봇 엔진 질의 요청\n",
    "    json_data = {\n",
    "        'Query': query,\n",
    "        'BotType': \"MyService\"\n",
    "    }\n",
    "    message = json.dumps(json_data)\n",
    "    mySocket.send(message.encode())\n",
    "\n",
    "    # 챗봇 엔진 답변 출력\n",
    "    data = mySocket.recv(2048).decode()\n",
    "    ret_data = json.loads(data)\n",
    "    print(\"답변 : \")\n",
    "    print(ret_data['Answer'])\n",
    "    print(ret_data)\n",
    "    print(type(ret_data))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # 챗봇 엔진 서버 연결 소켓 닫기\n",
    "    mySocket.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
