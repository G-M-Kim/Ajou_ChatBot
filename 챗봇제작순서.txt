1. 데이터 수집
-------------------------------------------------------------------------
2. 전처리 클래스(형태소 분리)
self.exclusion_tags = [
            'JKS', 'JKC', 'JKG', 'JKO', 'JKB', 'JKV', 'JKQ',
            'JX', 'JC',
            'SF', 'SP', 'SS', 'SE', 'SO',
            'EP', 'EF', 'EC', 'ETN', 'ETM',
            'XSN', 'XSV', 'XSA'
        ]
-------------------------------------------------------------------------
3. 단어사전 구축, 시퀀스 생성
-> <말뭉치 데이터>를 사용. 형태소를 분석하여, dict에 추가-> 토크나이저-> 생성된 인덱스 dict를 저장
-> 이렇게 하면, 분리된 형태소별로 index 코드가 부여됨.
-------------------------------------------------------------------------
4. 의도 분류 '모델 학습'
-> <질문 데이터>를 사용. CNN을 사용해, 분류 클래스별로 문장을 학습하고 문장 의도 이해.(감정구분) -> ex6의 cnn참고
-------------------------------------------------------------------------
5. 의도 분류 '모듈 생성'
-> 위 4단계에서 만든 파일을 활용.-> ex8.8 참고
-> 예측한 클래스(문장의도코드), 레이블(문장의도) 파악 확인 가능
-------------------------------------------------------------------------
6. 개체명 인식 '모델 학습'
-> <형태소 분리 후 BIO태그를 붙인 예상입력 데이터>를 사용. ->ex6의 개체명 인식모델 참고
-> LSTM을 사용해 BIO태그 자동생성 학습은 가능하나, 결국 학습용 데이터가 필요함.
-------------------------------------------------------------------------
7. 개체명 인식 '모듈 생성'
-> 위 6단계에서 만든 파일을 활용. 문장 내부의 개체명을 인식가능.
-------------------------------------------------------------------------
8. 답변 검색
-> 데이터베이스를 제어할 수 있는 모듈 생성.-> 의도명/개체명으로 답변을 검색.
sql = self._make_query(intent_name, None)
            answer = self.db.select_one(sql)
-------------------------------------------------------------------------
9. 검색된 답변을 , 코드에서 단어로 변환 후 적절히 출력함.
-------------------------------------------------------------------------
10. 서버 구축, API로 제작 후 플랫폼과 연결.