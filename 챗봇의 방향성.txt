
1. 전처리 (단어 분리)
=> 맞춤법 교정 후 pykomoran으로 분리

2. 의도분석 (대화주제-인사/욕설/질문)
=> 학습된 CNN을 사용해 대화 주제 파악.
=> CNN이 안되면 의도 단어 사전으로부터 코사인 유사도를 사용해 분별..?

3. 개체명인식
=> 양방향 LSTM이 가장 좋으나, 일반 LSTM 혹은 RNN이라도.. 이부분이 제일 문제다.

4. 답변검색
=> Mysql을 사용해 DB에서 적절한 답변 검색. 즉, 딥러닝이 아닌 룰-베이스 사전식임. (딥러닝 할만큼 했지 않나요..?)

5. 답변출력(서버)
=> Json을 사용한 프로토콜방식으로 엔진 서버를 개발함. 멀티스레드 지원, TCP 소켓 서버 충족 필요.
=> 해당 내용을 테스트 클라이언트(cmd창)으로 테스트 가능.

6. 서비스 이용(챗봇) *API안쓰고, 한가지 목적으로 쉽게 안될까?
=> 테스트 클라이언트를 API방식으로, 외부 서비스와 연동해야함. 즉 플랫폼과 서버를 연결시켜줌.

------------------------------------------------------------------------------
*각 기법은 치명적 단점이 없는 한 가장 성능이 뛰어난 것만 정리함.

Komoran
=> 문장에서 형태소 분리. 이때, 사전에 없는 고유명사등을 따로 추가해야함(아주대 = 사전에 없으나 하나의 명사).

Word2Vec
=> 단어간의 유사도 확인가능

코사인 유사도
=> 데이터X. 문장간의 유사도 확인 가능

문장분류 CNN 모델(합성곱 신경망)
=> 분류된 데이터로부터 어느 레이블(종류↓)에 속하는지 판단.

양방향 LSTM
=> 미완성 문장 복원 가능. 교재 예제가 부실한듯. 그냥 LSTM도 고려. --8.6에서 다루긴 함

개체명 인식(BIO) 기법
=> 품사에 태그를 달고 핵심단어 추출 가능.
=> 어려운 방법이므로, 우리처럼 '질문과 답변'에 한정짓는다면 개체명 사전을 만들어 매핑하는게 더 유리할지도.

MySQL
=> 데이터 조작 가능.(조회/삽입/변경/삭제). 답변을 검색하기 위한 데이터는 갱신되므로, DB형태. 이를 위한 툴.
=> 학습 데이터는 DB를 사용하지 말자... 답변 검색 Pool만 DB를 사용해 갱신.

REST API(파이썬의 경우 Flask)
=> HTTP메서드를 통해, 다양한 플랫폼에서 한가지 프로토콜로 통일 가능해짐.